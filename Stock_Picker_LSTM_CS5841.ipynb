{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Stock_Picker_LSTM_CS5841.ipynb","provenance":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Z27dJ7H945ms"},"source":["## LSTM"]},{"cell_type":"code","metadata":{"id":"1DGpbn6TCiq0","executionInfo":{"status":"ok","timestamp":1619575349073,"user_tz":240,"elapsed":835,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow"],"execution_count":240,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTqlvtCaDmKF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619575350841,"user_tz":240,"elapsed":959,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"c3ae78b4-3251-40be-e6be-4bd3ab59180f"},"source":["all_stocks = pd.read_csv('all_stocks_5yr.csv')\n","all_stocks['Name'].unique()[:25]"],"execution_count":241,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['AAL', 'AAPL', 'AAP', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI',\n","       'ADM', 'ADP', 'ADSK', 'ADS', 'AEE', 'AEP', 'AES', 'AET', 'AFL',\n","       'AGN', 'AIG', 'AIV', 'AIZ', 'AJG', 'AKAM', 'ALB'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":241}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W3P5zociKfM8","executionInfo":{"status":"ok","timestamp":1619575357931,"user_tz":240,"elapsed":6517,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"ed277cbd-e47e-45cb-efcc-94291c4ab833"},"source":["all_stocks['Name'].unique()\n","stock_name = input()\n","stock_name = stock_name.upper()\n","df = all_stocks.loc[all_stocks['Name'] == stock_name]"],"execution_count":242,"outputs":[{"output_type":"stream","text":["goog\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"id":"xJrRgVPOKhtS","executionInfo":{"status":"ok","timestamp":1619575359348,"user_tz":240,"elapsed":881,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"6e3de0fe-cc45-42c1-ab40-1cbf637795a6"},"source":["df.index = pd.DatetimeIndex(df['date'])\n","df = df[['close', 'volume']]\n","df"],"execution_count":243,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>close</th>\n","      <th>volume</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2014-03-27</th>\n","      <td>558.46</td>\n","      <td>13052</td>\n","    </tr>\n","    <tr>\n","      <th>2014-03-28</th>\n","      <td>559.99</td>\n","      <td>41003</td>\n","    </tr>\n","    <tr>\n","      <th>2014-03-31</th>\n","      <td>556.97</td>\n","      <td>10772</td>\n","    </tr>\n","    <tr>\n","      <th>2014-04-01</th>\n","      <td>567.16</td>\n","      <td>7932</td>\n","    </tr>\n","    <tr>\n","      <th>2014-04-02</th>\n","      <td>567.00</td>\n","      <td>146697</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2018-02-01</th>\n","      <td>1167.70</td>\n","      <td>2412114</td>\n","    </tr>\n","    <tr>\n","      <th>2018-02-02</th>\n","      <td>1111.90</td>\n","      <td>4857943</td>\n","    </tr>\n","    <tr>\n","      <th>2018-02-05</th>\n","      <td>1055.80</td>\n","      <td>3798301</td>\n","    </tr>\n","    <tr>\n","      <th>2018-02-06</th>\n","      <td>1080.60</td>\n","      <td>3447956</td>\n","    </tr>\n","    <tr>\n","      <th>2018-02-07</th>\n","      <td>1048.58</td>\n","      <td>2369232</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>975 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["              close   volume\n","date                        \n","2014-03-27   558.46    13052\n","2014-03-28   559.99    41003\n","2014-03-31   556.97    10772\n","2014-04-01   567.16     7932\n","2014-04-02   567.00   146697\n","...             ...      ...\n","2018-02-01  1167.70  2412114\n","2018-02-02  1111.90  4857943\n","2018-02-05  1055.80  3798301\n","2018-02-06  1080.60  3447956\n","2018-02-07  1048.58  2369232\n","\n","[975 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":243}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZJ5syqAKnIZ","executionInfo":{"status":"ok","timestamp":1619575361100,"user_tz":240,"elapsed":822,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"7db3c748-5a89-440d-d630-ba1ae8fbded2"},"source":["train = df.iloc[:-21]\n","test = df.iloc[-21:]\n","len(train), len(test)"],"execution_count":244,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(954, 21)"]},"metadata":{"tags":[]},"execution_count":244}]},{"cell_type":"code","metadata":{"id":"z_RIdFZiKpUE","executionInfo":{"status":"ok","timestamp":1619575362727,"user_tz":240,"elapsed":1105,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}}},"source":["# Preprocess Data\n","\n","def preprocess(training_data, testing_data):\n","  from sklearn.preprocessing import MinMaxScaler \n","  scaler = MinMaxScaler() #Scale training data for LSTM between 0 and 1 for better prediction\n","  training_data = scaler.fit_transform(train)\n","\n","  X_train = []\n","  y_train = []\n","  for i in range(21, training_data.shape[0]):\n","    X_train.append(training_data[i-21:i]) #X_train is a list of lists each having 30 day data \n","    y_train.append(training_data[i, 0]) #y_train is a set of data having values from each 30 day set for the next day after the previous 30 days\n","  X_train, y_train = np.array(X_train), np.array(y_train) #Convert in np.array foo reshaping \n","\n","  last_21_day_data = train.tail(21)\n","  df_test = last_21_day_data.append(test, ignore_index=True)\n","\n","  norm_test_set = scaler.transform(df_test) #Scale test data\n","\n","  X_test = []\n","  y_test = []\n","  # Arrange test data similarly as input data \n","  for i in range(21, norm_test_set.shape[0]): \n","    X_test.append(norm_test_set[i-21:i])\n","    y_test.append(norm_test_set[i, 0])\n","\n","  X_test, y_test = np.array(X_test), np.array(y_test)\n","\n","  return (X_train, y_train, X_test, y_test, scaler)\n","\n","X_train, y_train, X_test, y_test, scaler = preprocess(train, test)"],"execution_count":245,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPFV-vhNLe3r","executionInfo":{"status":"ok","timestamp":1619575363009,"user_tz":240,"elapsed":540,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}}},"source":["def modelInitialize():\n","  from tensorflow.keras import Sequential\n","  from tensorflow.keras.layers import Dense, LSTM, Dropout\n","\n","  regressor = Sequential() #Sequential model for the LSTM\n","\n","  regressor.add(LSTM(units = 60, activation = 'relu', return_sequences=True, input_shape = (X_train.shape[1], 2)))  \n","  #regressor.add(Dropout(0.2))\n","\n","  regressor.add(LSTM(units = 60, activation = 'relu', return_sequences=True))\n","  #regressor.add(Dropout(0.2))\n","\n","  regressor.add(LSTM(units = 80, activation = 'relu', return_sequences=True))\n","  #regressor.add(Dropout(0.2))\n","\n","  regressor.add(LSTM(units = 120, activation = 'relu'))\n","  #regressor.add(Dropout(0.2))\n","\n","  regressor.add(Dense(units = 1))\n","\n","  return regressor"],"execution_count":246,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65btTkjZLhno","executionInfo":{"status":"ok","timestamp":1619575365443,"user_tz":240,"elapsed":2063,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"1f72a412-e654-4ebb-c53a-837dafceadcd"},"source":["regressor = modelInitialize()\n","regressor.summary() #Model summary giving shapes of layers and parameters"],"execution_count":247,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"sequential_53\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_212 (LSTM)              (None, 21, 60)            15120     \n","_________________________________________________________________\n","lstm_213 (LSTM)              (None, 21, 60)            29040     \n","_________________________________________________________________\n","lstm_214 (LSTM)              (None, 21, 80)            45120     \n","_________________________________________________________________\n","lstm_215 (LSTM)              (None, 120)               96480     \n","_________________________________________________________________\n","dense_53 (Dense)             (None, 1)                 121       \n","=================================================================\n","Total params: 185,881\n","Trainable params: 185,881\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vKxg5UqXLpoW","executionInfo":{"status":"ok","timestamp":1619575366897,"user_tz":240,"elapsed":573,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}}},"source":["regressor.compile(optimizer = 'adam', loss = 'mean_squared_error') #compile model"],"execution_count":248,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FA2K9E9rLsDF","executionInfo":{"status":"ok","timestamp":1619575512608,"user_tz":240,"elapsed":141859,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"598d9da9-b4f0-417d-a7ae-40afc0c3f1f0"},"source":["regressor.fit(X_train, y_train, epochs = 50) #Train the model on training data"],"execution_count":249,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","30/30 [==============================] - 6s 91ms/step - loss: 0.1238\n","Epoch 2/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0065\n","Epoch 3/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0024\n","Epoch 4/50\n","30/30 [==============================] - 3s 97ms/step - loss: 0.0022\n","Epoch 5/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0019\n","Epoch 6/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0020\n","Epoch 7/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0019\n","Epoch 8/50\n","30/30 [==============================] - 3s 93ms/step - loss: 0.0017\n","Epoch 9/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0018\n","Epoch 10/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0015\n","Epoch 11/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0019\n","Epoch 12/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0017\n","Epoch 13/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0021\n","Epoch 14/50\n","30/30 [==============================] - 3s 97ms/step - loss: 0.0018\n","Epoch 15/50\n","30/30 [==============================] - 3s 93ms/step - loss: 0.0021\n","Epoch 16/50\n","30/30 [==============================] - 3s 99ms/step - loss: 0.0014\n","Epoch 17/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0015\n","Epoch 18/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0020\n","Epoch 19/50\n","30/30 [==============================] - 3s 95ms/step - loss: 0.0018\n","Epoch 20/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0017\n","Epoch 21/50\n","30/30 [==============================] - 3s 90ms/step - loss: 0.0014\n","Epoch 22/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0016\n","Epoch 23/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0014\n","Epoch 24/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0012\n","Epoch 25/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0014\n","Epoch 26/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0019\n","Epoch 27/50\n","30/30 [==============================] - 3s 94ms/step - loss: 0.0012\n","Epoch 28/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0015\n","Epoch 29/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0013\n","Epoch 30/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0012\n","Epoch 31/50\n","30/30 [==============================] - 3s 90ms/step - loss: 0.0012\n","Epoch 32/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0012\n","Epoch 33/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0012\n","Epoch 34/50\n","30/30 [==============================] - 3s 91ms/step - loss: 9.5569e-04\n","Epoch 35/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0012\n","Epoch 36/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0012\n","Epoch 37/50\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0011\n","Epoch 38/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0013\n","Epoch 39/50\n","30/30 [==============================] - 3s 94ms/step - loss: 9.5392e-04\n","Epoch 40/50\n","30/30 [==============================] - 3s 95ms/step - loss: 0.0012\n","Epoch 41/50\n","30/30 [==============================] - 3s 91ms/step - loss: 7.9048e-04\n","Epoch 42/50\n","30/30 [==============================] - 3s 91ms/step - loss: 7.4866e-04\n","Epoch 43/50\n","30/30 [==============================] - 3s 91ms/step - loss: 8.2733e-04\n","Epoch 44/50\n","30/30 [==============================] - 3s 90ms/step - loss: 8.4473e-04\n","Epoch 45/50\n","30/30 [==============================] - 3s 90ms/step - loss: 9.7316e-04\n","Epoch 46/50\n","30/30 [==============================] - 3s 91ms/step - loss: 8.2762e-04\n","Epoch 47/50\n","30/30 [==============================] - 3s 94ms/step - loss: 7.6147e-04\n","Epoch 48/50\n","30/30 [==============================] - 3s 92ms/step - loss: 0.0012\n","Epoch 49/50\n","30/30 [==============================] - 3s 91ms/step - loss: 8.3489e-04\n","Epoch 50/50\n","30/30 [==============================] - 3s 95ms/step - loss: 9.9852e-04\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb046929e50>"]},"metadata":{"tags":[]},"execution_count":249}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTwuLpO7pBcR","executionInfo":{"status":"ok","timestamp":1619575740145,"user_tz":240,"elapsed":1067,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"c9dc9026-bc5a-4bbc-cdf7-bb99ab7ffea6"},"source":["def predict(X_test, y_test, scaler, regressor):\n","  y_pred = regressor.predict(X_test) #predict values for X_test \n","  scale = scaler.scale_\n","  scale111 = 1/scale[0]\n","  scale111\n","  y_test = y_test*scale111\n","  y_pred = y_pred*scale111\n","\n","  return y_test, y_pred\n","\n","y_test, y_pred = predict(X_test, y_test, scaler, regressor)"],"execution_count":250,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb043afaf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"eRYPkqKuOQ28","executionInfo":{"status":"ok","timestamp":1619575741478,"user_tz":240,"elapsed":1232,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"5b6006ae-2181-4aaf-e57d-1b7d192196b7"},"source":["#Plot the predicted values and close price values\n","plt.figure(figsize = (14, 5))\n","plt.plot(y_test, color='r', label='Google Close Price')\n","plt.plot(y_pred, color='b', label='Predicted Google Stock Price')\n","\n","plt.xlabel('Time Points')\n","plt.ylabel('Price')\n","plt.legend(fontsize=18)"],"execution_count":251,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fb044c598d0>"]},"metadata":{"tags":[]},"execution_count":251},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1008x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01ZfXpVBOTCD","executionInfo":{"status":"ok","timestamp":1619575745626,"user_tz":240,"elapsed":1053,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"9135e2b1-a039-4881-f278-6dd4dd43cc5e"},"source":["X_train[0]"],"execution_count":252,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.07277137e-01, 4.58904271e-04],\n","       [1.09767412e-01, 2.96414515e-03],\n","       [1.04851967e-01, 2.54548463e-04],\n","       [1.21437523e-01, 0.00000000e+00],\n","       [1.21177102e-01, 1.24374709e-02],\n","       [1.25636810e-01, 4.55283050e-01],\n","       [8.23418350e-02, 5.70916888e-01],\n","       [7.42199580e-02, 3.92724987e-01],\n","       [1.01482772e-01, 2.81838388e-01],\n","       [1.16522079e-01, 2.97284819e-01],\n","       [7.87773238e-02, 3.60294617e-01],\n","       [6.19313465e-02, 3.50294447e-01],\n","       [6.50563974e-02, 2.29460023e-01],\n","       [7.14367096e-02, 3.44135271e-01],\n","       [1.04152086e-01, 4.36672241e-01],\n","       [7.08833152e-02, 6.08358368e-01],\n","       [5.87086378e-02, 2.28850003e-01],\n","       [6.87836716e-02, 2.10763349e-01],\n","       [5.59742183e-02, 1.83125570e-01],\n","       [5.30770358e-02, 1.67969091e-01],\n","       [3.84609124e-02, 1.87266285e-01]])"]},"metadata":{"tags":[]},"execution_count":252}]},{"cell_type":"code","metadata":{"id":"e5xCyg_uOoo-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619582782900,"user_tz":240,"elapsed":4687860,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"0d1e3faa-ce47-4cce-c6ab-64bd32f6ae17"},"source":["preds = []\n","start_price = []\n","for k in range(25):\n","    df_c = all_stocks[k*1259:(k+1)*1259]\n","    \n","    size = int(len(df_c) * (1259-21)/1259)\n","    train = df_c[['close', 'volume']].iloc[:size]\n","    test = df_c[['close', 'volume']].iloc[size:]\n","    X_train, y_train, X_test, y_test, scaler = preprocess(train, test)\n","    regressor = modelInitialize()\n","    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error') #compile model\n","    regressor.fit(X_train, y_train, epochs = 50) #Train the model on training data\n","    y_test, predictions = predict(X_test, y_test, scaler, regressor)\n","    preds.append(predictions[-1])\n","    start_price.append(predictions[0])"],"execution_count":258,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 92ms/step - loss: 0.1925\n","Epoch 2/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0077\n","Epoch 3/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0043\n","Epoch 4/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0038\n","Epoch 5/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0038\n","Epoch 6/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0037\n","Epoch 7/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0037\n","Epoch 8/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0039\n","Epoch 9/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0038\n","Epoch 10/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0041\n","Epoch 11/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0030\n","Epoch 12/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0026\n","Epoch 13/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0027\n","Epoch 14/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0026\n","Epoch 15/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0030\n","Epoch 16/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0025\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0022\n","Epoch 18/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0022\n","Epoch 19/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0024\n","Epoch 20/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0024\n","Epoch 21/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0025\n","Epoch 22/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0022\n","Epoch 23/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0031\n","Epoch 24/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0023\n","Epoch 25/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0034\n","Epoch 26/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0020\n","Epoch 27/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 28/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0017\n","Epoch 29/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0020\n","Epoch 30/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0019\n","Epoch 31/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0019\n","Epoch 32/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0016\n","Epoch 33/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 34/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0042\n","Epoch 35/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 36/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 37/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0010\n","Epoch 38/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 39/50\n","39/39 [==============================] - 4s 91ms/step - loss: 9.6242e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 91ms/step - loss: 9.5150e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 42/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 43/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.4221e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0013\n","Epoch 45/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 46/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.8579e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.7372e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 49/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.5773e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.2991e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb04a477e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 6s 91ms/step - loss: 0.1110\n","Epoch 2/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0028\n","Epoch 3/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0022\n","Epoch 4/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0020\n","Epoch 5/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0018\n","Epoch 6/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 7/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 8/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 9/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 10/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0016\n","Epoch 11/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0022\n","Epoch 12/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 13/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0018\n","Epoch 14/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0017\n","Epoch 15/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 16/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 18/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 19/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 20/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0014\n","Epoch 21/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0032\n","Epoch 22/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0013\n","Epoch 23/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0014\n","Epoch 24/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.9372e-04\n","Epoch 25/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 26/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.9869e-04\n","Epoch 27/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.9786e-04\n","Epoch 28/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0047\n","Epoch 29/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 30/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0020\n","Epoch 31/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 32/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 33/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 34/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0026\n","Epoch 35/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 36/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0012\n","Epoch 37/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0015\n","Epoch 38/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0012\n","Epoch 39/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0011\n","Epoch 40/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0013\n","Epoch 41/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0010\n","Epoch 42/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.8245e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0015\n","Epoch 44/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.6847e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0033\n","Epoch 46/50\n","39/39 [==============================] - 4s 90ms/step - loss: 0.0014\n","Epoch 47/50\n","39/39 [==============================] - 4s 90ms/step - loss: 9.0555e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.4492e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.1842e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.4003e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb0480c2a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 6s 91ms/step - loss: 0.1380\n","Epoch 2/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0073\n","Epoch 3/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0036\n","Epoch 4/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0031\n","Epoch 5/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0036\n","Epoch 6/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0031\n","Epoch 7/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0030\n","Epoch 8/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0029\n","Epoch 9/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0025\n","Epoch 10/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0022\n","Epoch 11/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0024\n","Epoch 12/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0022\n","Epoch 13/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0022\n","Epoch 14/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 15/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0022\n","Epoch 16/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0029\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 18/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0021\n","Epoch 19/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0016\n","Epoch 20/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0017\n","Epoch 21/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0015\n","Epoch 22/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0018\n","Epoch 23/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0020\n","Epoch 24/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0013\n","Epoch 25/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0015\n","Epoch 26/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0016\n","Epoch 27/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 28/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0106\n","Epoch 29/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0020\n","Epoch 30/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0016\n","Epoch 31/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0017\n","Epoch 32/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 33/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 34/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0015\n","Epoch 35/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 36/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","Epoch 37/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0017\n","Epoch 38/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 39/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0020\n","Epoch 40/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 41/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.4818e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0014\n","Epoch 43/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.9707e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.4216e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.3656e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 47/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.6189e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 49/50\n","39/39 [==============================] - 4s 94ms/step - loss: 7.5881e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.2185e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb046ba6cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 97ms/step - loss: 0.0953\n","Epoch 2/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0061\n","Epoch 3/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0022\n","Epoch 4/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0020\n","Epoch 5/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0020\n","Epoch 6/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 7/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0017\n","Epoch 8/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0035\n","Epoch 9/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 10/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0018\n","Epoch 11/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0017\n","Epoch 12/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 13/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0018\n","Epoch 14/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 15/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0014\n","Epoch 16/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0018\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0014\n","Epoch 18/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 19/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0017\n","Epoch 20/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 21/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 22/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 23/50\n","39/39 [==============================] - 4s 90ms/step - loss: 0.0026\n","Epoch 24/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0014\n","Epoch 25/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 26/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 27/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0011\n","Epoch 28/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 29/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.5314e-04\n","Epoch 30/50\n","39/39 [==============================] - 4s 90ms/step - loss: 9.9802e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.6106e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 90ms/step - loss: 0.0012\n","Epoch 33/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.6857e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0014\n","Epoch 35/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0011\n","Epoch 36/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.9826e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.8110e-04\n","Epoch 38/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 39/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.9009e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.2248e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.3490e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.7824e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 92ms/step - loss: 5.8945e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 45/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.9783e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.0798e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 96ms/step - loss: 5.1975e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 91ms/step - loss: 5.7416e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 91ms/step - loss: 5.9087e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 91ms/step - loss: 4.8651e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb045e0cd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 93ms/step - loss: 0.1460\n","Epoch 2/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0044\n","Epoch 3/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0030\n","Epoch 4/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0035\n","Epoch 5/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0037\n","Epoch 6/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0032\n","Epoch 7/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0035\n","Epoch 8/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0025\n","Epoch 9/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0020\n","Epoch 10/50\n","39/39 [==============================] - 4s 90ms/step - loss: 0.0019\n","Epoch 11/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0022\n","Epoch 12/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0016\n","Epoch 13/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0022\n","Epoch 14/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0037\n","Epoch 15/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0018\n","Epoch 16/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0015\n","Epoch 17/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0016\n","Epoch 18/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0014\n","Epoch 19/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0016\n","Epoch 20/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0017\n","Epoch 21/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0011\n","Epoch 22/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0013\n","Epoch 23/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0014\n","Epoch 24/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0013\n","Epoch 25/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0017\n","Epoch 26/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0012\n","Epoch 27/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0021\n","Epoch 28/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 29/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.8015e-04\n","Epoch 30/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0013\n","Epoch 31/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.6586e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.2572e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.3646e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.2483e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 36/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.7785e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 38/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 39/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.4174e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0011\n","Epoch 41/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.5376e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 102ms/step - loss: 0.0011\n","Epoch 43/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.1250e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.5245e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 91ms/step - loss: 5.9016e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.3827e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.7206e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 91ms/step - loss: 5.6811e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0013\n","Epoch 50/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.1044e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb0459f45f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 92ms/step - loss: 0.0949\n","Epoch 2/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0069\n","Epoch 3/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0042\n","Epoch 4/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0042\n","Epoch 5/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0038\n","Epoch 6/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0030\n","Epoch 7/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0030\n","Epoch 8/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0028\n","Epoch 9/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0022\n","Epoch 10/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0030\n","Epoch 11/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0021\n","Epoch 12/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0021\n","Epoch 13/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0021\n","Epoch 14/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0021\n","Epoch 15/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0018\n","Epoch 16/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0020\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 18/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 19/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0022\n","Epoch 20/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0017\n","Epoch 21/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0020\n","Epoch 22/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0017\n","Epoch 23/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 24/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 25/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 26/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0016\n","Epoch 27/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 28/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0013\n","Epoch 29/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 30/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.9095e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.6978e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.9845e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 96ms/step - loss: 9.4857e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 90ms/step - loss: 9.2480e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.5588e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.4019e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.9220e-04\n","Epoch 38/50\n","39/39 [==============================] - 4s 92ms/step - loss: 5.6940e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 91ms/step - loss: 5.1483e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 91ms/step - loss: 5.6602e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 99ms/step - loss: 5.3613e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.9738e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.2671e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.9557e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 91ms/step - loss: 4.8956e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 97ms/step - loss: 7.2324e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 92ms/step - loss: 4.4693e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.7655e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 91ms/step - loss: 5.0030e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 4.8756e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb045c94170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 93ms/step - loss: 0.0863\n","Epoch 2/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0029\n","Epoch 3/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 4/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 5/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0021\n","Epoch 6/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0012\n","Epoch 7/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0013\n","Epoch 8/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0031\n","Epoch 9/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0014\n","Epoch 10/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 11/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 12/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 13/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 14/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 15/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 16/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0012\n","Epoch 18/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0012\n","Epoch 19/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 20/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0010\n","Epoch 21/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.1460e-04\n","Epoch 22/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 23/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 24/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 25/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.1257e-04\n","Epoch 26/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.7734e-04\n","Epoch 27/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.5560e-04\n","Epoch 28/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.7714e-04\n","Epoch 29/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 30/50\n","39/39 [==============================] - 4s 91ms/step - loss: 8.2863e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.2706e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.0793e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 34/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.9511e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.6640e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.1118e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.5270e-04\n","Epoch 38/50\n","39/39 [==============================] - 4s 92ms/step - loss: 5.7145e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.8436e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 97ms/step - loss: 6.8040e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 92ms/step - loss: 5.6525e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.6990e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.0257e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 91ms/step - loss: 5.2543e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.6710e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.5014e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.4977e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.0141e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 92ms/step - loss: 4.2064e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb050d5a200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 92ms/step - loss: 0.0811\n","Epoch 2/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0026\n","Epoch 3/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 4/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 5/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.4902e-04\n","Epoch 6/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0065\n","Epoch 7/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 8/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 9/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.9430e-04\n","Epoch 10/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 11/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.0005e-04\n","Epoch 12/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.0819e-04\n","Epoch 13/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.8643e-04\n","Epoch 14/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.1508e-04\n","Epoch 15/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 16/50\n","39/39 [==============================] - 4s 96ms/step - loss: 5.9887e-04\n","Epoch 17/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.2374e-04\n","Epoch 18/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.9923e-04\n","Epoch 19/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.3455e-04\n","Epoch 20/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 21/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.1161e-04\n","Epoch 22/50\n","39/39 [==============================] - 4s 95ms/step - loss: 7.4076e-04\n","Epoch 23/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.1966e-04\n","Epoch 24/50\n","39/39 [==============================] - 4s 92ms/step - loss: 5.6517e-04\n","Epoch 25/50\n","39/39 [==============================] - 4s 95ms/step - loss: 6.5729e-04\n","Epoch 26/50\n","39/39 [==============================] - 4s 94ms/step - loss: 6.5394e-04\n","Epoch 27/50\n","39/39 [==============================] - 4s 99ms/step - loss: 5.9152e-04\n","Epoch 28/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.9436e-04\n","Epoch 29/50\n","39/39 [==============================] - 4s 96ms/step - loss: 5.0482e-04\n","Epoch 30/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.7328e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 93ms/step - loss: 4.8675e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.0023e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.5893e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 92ms/step - loss: 5.8927e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 97ms/step - loss: 6.3334e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 92ms/step - loss: 4.9526e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0018\n","Epoch 38/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.0449e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 92ms/step - loss: 4.7290e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 93ms/step - loss: 3.9454e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 93ms/step - loss: 4.4064e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 93ms/step - loss: 4.3982e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 92ms/step - loss: 4.8883e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 98ms/step - loss: 5.3435e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 97ms/step - loss: 4.2414e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 93ms/step - loss: 4.0648e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 94ms/step - loss: 3.9071e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 97ms/step - loss: 4.1082e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 92ms/step - loss: 4.8600e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 92ms/step - loss: 3.5046e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb0458fb710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 6s 92ms/step - loss: 0.0996\n","Epoch 2/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0042\n","Epoch 3/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0030\n","Epoch 4/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0029\n","Epoch 5/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0024\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0028\n","Epoch 7/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0075\n","Epoch 8/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0026\n","Epoch 9/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0023\n","Epoch 10/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0021\n","Epoch 11/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0022\n","Epoch 12/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0055\n","Epoch 13/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0022\n","Epoch 14/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0019\n","Epoch 15/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0020\n","Epoch 16/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0016\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 18/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 19/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0014\n","Epoch 20/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0012\n","Epoch 21/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0014\n","Epoch 22/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0012\n","Epoch 23/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 24/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0014\n","Epoch 25/50\n","39/39 [==============================] - 4s 91ms/step - loss: 9.9180e-04\n","Epoch 26/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.1632e-04\n","Epoch 27/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.4834e-04\n","Epoch 28/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0012\n","Epoch 29/50\n","39/39 [==============================] - 4s 98ms/step - loss: 9.2882e-04\n","Epoch 30/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.5834e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.5201e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.5538e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.9500e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.9488e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.0400e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.6192e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 91ms/step - loss: 7.6507e-04\n","Epoch 38/50\n","39/39 [==============================] - 4s 98ms/step - loss: 6.8957e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.1487e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.2791e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.7763e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 91ms/step - loss: 6.4136e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.1431e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 45/50\n","39/39 [==============================] - 4s 94ms/step - loss: 6.6032e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 95ms/step - loss: 5.7605e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 97ms/step - loss: 9.1237e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 92ms/step - loss: 5.7645e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0017\n","Epoch 50/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.2966e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb0486a3200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 93ms/step - loss: 0.1805\n","Epoch 2/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0089\n","Epoch 3/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0067\n","Epoch 4/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0064\n","Epoch 5/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0081\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0053\n","Epoch 7/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0083\n","Epoch 8/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0059\n","Epoch 9/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0056\n","Epoch 10/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0048\n","Epoch 11/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0068\n","Epoch 12/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0063\n","Epoch 13/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0040\n","Epoch 14/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0037\n","Epoch 15/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0035\n","Epoch 16/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0038\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0030\n","Epoch 18/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0029\n","Epoch 19/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0030\n","Epoch 20/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0025\n","Epoch 21/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0059\n","Epoch 22/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0034\n","Epoch 23/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0022\n","Epoch 24/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0019\n","Epoch 25/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0020\n","Epoch 26/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0040\n","Epoch 27/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0020\n","Epoch 28/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0016\n","Epoch 29/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 30/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 31/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0025\n","Epoch 32/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0026\n","Epoch 33/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0013\n","Epoch 34/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 35/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 36/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0014\n","Epoch 37/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 38/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0010\n","Epoch 39/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.2026e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 41/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.8649e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.3176e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 44/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0051\n","Epoch 45/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.3460e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.5715e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.9137e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 91ms/step - loss: 0.0012\n","Epoch 49/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.1501e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.3690e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb04a60cd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 93ms/step - loss: 0.1192\n","Epoch 2/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0093\n","Epoch 3/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0033\n","Epoch 4/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0041\n","Epoch 5/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0031\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0033\n","Epoch 7/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0026\n","Epoch 8/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0031\n","Epoch 9/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0025\n","Epoch 10/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0025\n","Epoch 11/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0025\n","Epoch 12/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0035\n","Epoch 13/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0029\n","Epoch 14/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0023\n","Epoch 15/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0023\n","Epoch 16/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0019\n","Epoch 17/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0021\n","Epoch 18/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0018\n","Epoch 19/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 20/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0018\n","Epoch 21/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0018\n","Epoch 22/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0057\n","Epoch 23/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0019\n","Epoch 24/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0016\n","Epoch 25/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 26/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0027\n","Epoch 27/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0015\n","Epoch 28/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 29/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 30/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 31/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.6993e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 33/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 34/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 35/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 36/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.0366e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 38/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 39/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.7392e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 41/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.6152e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.2566e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.7063e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.7371e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.0556e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 92ms/step - loss: 8.9830e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.5849e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.8217e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.4720e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.6670e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb048cf9cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 93ms/step - loss: 0.0812\n","Epoch 2/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0049\n","Epoch 3/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0028\n","Epoch 4/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 5/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0017\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 7/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0017\n","Epoch 8/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0014\n","Epoch 9/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0022\n","Epoch 10/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0036\n","Epoch 11/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0013\n","Epoch 12/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0015\n","Epoch 13/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 14/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0013\n","Epoch 15/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 16/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 17/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0019\n","Epoch 18/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 19/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0016\n","Epoch 20/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0014\n","Epoch 21/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0011\n","Epoch 22/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0020\n","Epoch 23/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.8558e-04\n","Epoch 24/50\n","39/39 [==============================] - 4s 100ms/step - loss: 8.7307e-04\n","Epoch 25/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.6740e-04\n","Epoch 26/50\n","39/39 [==============================] - 4s 97ms/step - loss: 9.7559e-04\n","Epoch 27/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 28/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 29/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 30/50\n","39/39 [==============================] - 4s 97ms/step - loss: 8.7245e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0010\n","Epoch 32/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0015\n","Epoch 33/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.9892e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 92ms/step - loss: 9.8486e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.8112e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.2138e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.9043e-04\n","Epoch 38/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.3911e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 97ms/step - loss: 7.2742e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0015\n","Epoch 41/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.0035e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 92ms/step - loss: 7.7183e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.6058e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.7157e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.9912e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 92ms/step - loss: 6.5777e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.1515e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 97ms/step - loss: 6.5509e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 92ms/step - loss: 5.3180e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.3780e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb050d65560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 94ms/step - loss: 0.1914\n","Epoch 2/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0102\n","Epoch 3/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0065\n","Epoch 4/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0065\n","Epoch 5/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0059\n","Epoch 6/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0049\n","Epoch 7/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0041\n","Epoch 8/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0049\n","Epoch 9/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0039\n","Epoch 10/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0031\n","Epoch 11/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0033\n","Epoch 12/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0030\n","Epoch 13/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0028\n","Epoch 14/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0027\n","Epoch 15/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0022\n","Epoch 16/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0026\n","Epoch 17/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0021\n","Epoch 18/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0031\n","Epoch 19/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0029\n","Epoch 20/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0027\n","Epoch 21/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0058\n","Epoch 22/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0022\n","Epoch 23/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0019\n","Epoch 24/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0019\n","Epoch 25/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0021\n","Epoch 26/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 27/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0018\n","Epoch 28/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 29/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 30/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 31/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0024\n","Epoch 32/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 33/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0015\n","Epoch 34/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0021\n","Epoch 35/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 36/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0036\n","Epoch 37/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0016\n","Epoch 38/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0013\n","Epoch 39/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0013\n","Epoch 40/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 41/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 42/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 43/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 44/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 45/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0010\n","Epoch 46/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.3415e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 48/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.3175e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.4091e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb048291950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 95ms/step - loss: 0.1201\n","Epoch 2/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0075\n","Epoch 3/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0036\n","Epoch 4/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0021\n","Epoch 5/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0027\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0024\n","Epoch 7/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0026\n","Epoch 8/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0036\n","Epoch 9/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0020\n","Epoch 10/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0022\n","Epoch 11/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0019\n","Epoch 12/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0019\n","Epoch 13/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0018\n","Epoch 14/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0025\n","Epoch 15/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 16/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0026\n","Epoch 17/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 18/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0016\n","Epoch 19/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 20/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0015\n","Epoch 21/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0023\n","Epoch 22/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0015\n","Epoch 23/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0014\n","Epoch 24/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 25/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0016\n","Epoch 26/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 27/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 28/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 29/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 30/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.1374e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 32/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.8887e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.7130e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.1609e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.6734e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 100ms/step - loss: 8.7353e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0017\n","Epoch 38/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.0044e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.7249e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 41/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.8043e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0029\n","Epoch 43/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0018\n","Epoch 44/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0016\n","Epoch 45/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.4287e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.0384e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.8912e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.8582e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 94ms/step - loss: 7.9396e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.8990e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb04c1d0050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 93ms/step - loss: 0.1472\n","Epoch 2/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0047\n","Epoch 3/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0031\n","Epoch 4/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0027\n","Epoch 5/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0028\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0031\n","Epoch 7/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0026\n","Epoch 8/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0028\n","Epoch 9/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0027\n","Epoch 10/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0038\n","Epoch 11/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0023\n","Epoch 12/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0033\n","Epoch 13/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0029\n","Epoch 14/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0024\n","Epoch 15/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0019\n","Epoch 16/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0023\n","Epoch 17/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0023\n","Epoch 18/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0027\n","Epoch 19/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0015\n","Epoch 20/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0019\n","Epoch 21/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 22/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0028\n","Epoch 23/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 24/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 25/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 26/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 27/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 28/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 29/50\n","39/39 [==============================] - 4s 97ms/step - loss: 9.5054e-04\n","Epoch 30/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 31/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 32/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.4342e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 34/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0011\n","Epoch 35/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.4661e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0010\n","Epoch 37/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0010\n","Epoch 38/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 39/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.9428e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.0954e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 93ms/step - loss: 6.9131e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 94ms/step - loss: 6.9502e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.1595e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.9338e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.8241e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.4806e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.2433e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0031\n","Epoch 49/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.8038e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb05088cdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 93ms/step - loss: 0.1923\n","Epoch 2/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0115\n","Epoch 3/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0061\n","Epoch 4/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0051\n","Epoch 5/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0058\n","Epoch 6/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0045\n","Epoch 7/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0058\n","Epoch 8/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0045\n","Epoch 9/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0062\n","Epoch 10/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0036\n","Epoch 11/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0032\n","Epoch 12/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0033\n","Epoch 13/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0040\n","Epoch 14/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0033\n","Epoch 15/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0043\n","Epoch 16/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0027\n","Epoch 17/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0027\n","Epoch 18/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0029\n","Epoch 19/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0067\n","Epoch 20/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0045\n","Epoch 21/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0027\n","Epoch 22/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0033\n","Epoch 23/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0021\n","Epoch 24/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0021\n","Epoch 25/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0019\n","Epoch 26/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0018\n","Epoch 27/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0020\n","Epoch 28/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 29/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 30/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0015\n","Epoch 31/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0017\n","Epoch 32/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0015\n","Epoch 33/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 34/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0030\n","Epoch 35/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0017\n","Epoch 36/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 37/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0018\n","Epoch 38/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 39/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0010\n","Epoch 40/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 41/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.8561e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0025\n","Epoch 43/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 44/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 45/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 46/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 47/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0019\n","Epoch 48/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0012\n","Epoch 49/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0016\n","Epoch 50/50\n","39/39 [==============================] - 4s 99ms/step - loss: 8.3859e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb046b4e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 94ms/step - loss: 0.1039\n","Epoch 2/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0025\n","Epoch 3/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","Epoch 4/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 5/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 7/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.8169e-04\n","Epoch 8/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0011\n","Epoch 9/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 10/50\n","39/39 [==============================] - 4s 96ms/step - loss: 9.7402e-04\n","Epoch 11/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0010\n","Epoch 12/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0010\n","Epoch 13/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.5666e-04\n","Epoch 14/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0022\n","Epoch 15/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0013\n","Epoch 16/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 17/50\n","39/39 [==============================] - 4s 97ms/step - loss: 9.2764e-04\n","Epoch 18/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 19/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.2357e-04\n","Epoch 20/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.5875e-04\n","Epoch 21/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.9253e-04\n","Epoch 22/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0016\n","Epoch 23/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.7090e-04\n","Epoch 24/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 25/50\n","39/39 [==============================] - 4s 94ms/step - loss: 7.6609e-04\n","Epoch 26/50\n","39/39 [==============================] - 4s 101ms/step - loss: 8.3939e-04\n","Epoch 27/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.7684e-04\n","Epoch 28/50\n","39/39 [==============================] - 4s 95ms/step - loss: 6.9190e-04\n","Epoch 29/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.8180e-04\n","Epoch 30/50\n","39/39 [==============================] - 4s 99ms/step - loss: 7.8401e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 94ms/step - loss: 7.5074e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0011\n","Epoch 33/50\n","39/39 [==============================] - 4s 99ms/step - loss: 7.8607e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 99ms/step - loss: 7.3238e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 101ms/step - loss: 6.4666e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 94ms/step - loss: 7.7017e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.8446e-04\n","Epoch 38/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.3748e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.4206e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 95ms/step - loss: 6.7210e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 42/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 43/50\n","39/39 [==============================] - 4s 99ms/step - loss: 5.9970e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 95ms/step - loss: 5.6927e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 97ms/step - loss: 5.0031e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 94ms/step - loss: 6.7569e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 94ms/step - loss: 5.3174e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 94ms/step - loss: 5.6817e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.0288e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 5.7557e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb045e3aa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 93ms/step - loss: 0.0947\n","Epoch 2/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0049\n","Epoch 3/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0025\n","Epoch 4/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0020\n","Epoch 5/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0019\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0029\n","Epoch 7/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 8/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0018\n","Epoch 9/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0020\n","Epoch 10/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0023\n","Epoch 11/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0017\n","Epoch 12/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0021\n","Epoch 13/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0028\n","Epoch 14/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0016\n","Epoch 15/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0016\n","Epoch 16/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 17/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0013\n","Epoch 18/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0017\n","Epoch 19/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0015\n","Epoch 20/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 21/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0010\n","Epoch 22/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.6531e-04\n","Epoch 23/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0049\n","Epoch 24/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 25/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0015\n","Epoch 26/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 27/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0016\n","Epoch 28/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0014\n","Epoch 29/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0018\n","Epoch 30/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 31/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0011\n","Epoch 32/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 33/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0012\n","Epoch 34/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 35/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.0013\n","Epoch 36/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0013\n","Epoch 37/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0013\n","Epoch 38/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0010\n","Epoch 39/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0010\n","Epoch 40/50\n","39/39 [==============================] - 4s 94ms/step - loss: 8.0849e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 93ms/step - loss: 9.2042e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.6011e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.1199e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0040\n","Epoch 45/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0030\n","Epoch 46/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0023\n","Epoch 47/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0010\n","Epoch 48/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0011\n","Epoch 49/50\n","39/39 [==============================] - 4s 93ms/step - loss: 8.7826e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 93ms/step - loss: 7.6371e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb044cb43b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 94ms/step - loss: 0.2040\n","Epoch 2/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0096\n","Epoch 3/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0026\n","Epoch 4/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0029\n","Epoch 5/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0029\n","Epoch 6/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0027\n","Epoch 7/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0032\n","Epoch 8/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0026\n","Epoch 9/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0024\n","Epoch 10/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0023\n","Epoch 11/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0020\n","Epoch 12/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0028\n","Epoch 13/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0019\n","Epoch 14/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 15/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0023\n","Epoch 16/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0021\n","Epoch 17/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 18/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 19/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 20/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0066\n","Epoch 21/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0026\n","Epoch 22/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0023\n","Epoch 23/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0022\n","Epoch 24/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0028\n","Epoch 25/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0019\n","Epoch 26/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0034\n","Epoch 27/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0017\n","Epoch 28/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0018\n","Epoch 29/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 30/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 31/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0021\n","Epoch 32/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 33/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0016\n","Epoch 34/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0013\n","Epoch 35/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0014\n","Epoch 36/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0014\n","Epoch 37/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0014\n","Epoch 38/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0013\n","Epoch 39/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0013\n","Epoch 40/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0012\n","Epoch 41/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0018\n","Epoch 42/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0014\n","Epoch 43/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0033\n","Epoch 44/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0012\n","Epoch 45/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 46/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","Epoch 47/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 48/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0012\n","Epoch 49/50\n","39/39 [==============================] - 4s 97ms/step - loss: 9.6718e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb049fa5680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 95ms/step - loss: 0.2303\n","Epoch 2/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0070\n","Epoch 3/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0050\n","Epoch 4/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0039\n","Epoch 5/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0042\n","Epoch 6/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0036\n","Epoch 7/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0033\n","Epoch 8/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0037\n","Epoch 9/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0033\n","Epoch 10/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0030\n","Epoch 11/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0028\n","Epoch 12/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0031\n","Epoch 13/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0030\n","Epoch 14/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0027\n","Epoch 15/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0024\n","Epoch 16/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0033\n","Epoch 17/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0024\n","Epoch 18/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0023\n","Epoch 19/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0030\n","Epoch 20/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0022\n","Epoch 21/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0032\n","Epoch 22/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0017\n","Epoch 23/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0035\n","Epoch 24/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0023\n","Epoch 25/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0020\n","Epoch 26/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 27/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0028\n","Epoch 28/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0019\n","Epoch 29/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0019\n","Epoch 30/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 31/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0030\n","Epoch 32/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 33/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0025\n","Epoch 34/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0019\n","Epoch 35/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0014\n","Epoch 36/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0025\n","Epoch 37/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 38/50\n","39/39 [==============================] - 4s 93ms/step - loss: 0.0017\n","Epoch 39/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0017\n","Epoch 40/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0014\n","Epoch 41/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0010\n","Epoch 42/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0016\n","Epoch 43/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0020\n","Epoch 44/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 45/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 46/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.8267e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.8709e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.7045e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.4266e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb04917e5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 94ms/step - loss: 0.2229\n","Epoch 2/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0088\n","Epoch 3/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0044\n","Epoch 4/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0050\n","Epoch 5/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0037\n","Epoch 6/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0044\n","Epoch 7/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0039\n","Epoch 8/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0034\n","Epoch 9/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0030\n","Epoch 10/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0037\n","Epoch 11/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0026\n","Epoch 12/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0024\n","Epoch 13/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0026\n","Epoch 14/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0023\n","Epoch 15/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0020\n","Epoch 16/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0021\n","Epoch 17/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0044\n","Epoch 18/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0021\n","Epoch 19/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0028\n","Epoch 20/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0019\n","Epoch 21/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0018\n","Epoch 22/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0020\n","Epoch 23/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0022\n","Epoch 24/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0020\n","Epoch 25/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0014\n","Epoch 26/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0017\n","Epoch 27/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0019\n","Epoch 28/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0014\n","Epoch 29/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0015\n","Epoch 30/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0021\n","Epoch 31/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0014\n","Epoch 32/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0043\n","Epoch 33/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0020\n","Epoch 34/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0017\n","Epoch 35/50\n","39/39 [==============================] - 4s 102ms/step - loss: 0.0011\n","Epoch 36/50\n","39/39 [==============================] - 4s 102ms/step - loss: 0.0012\n","Epoch 37/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0010\n","Epoch 38/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0011\n","Epoch 39/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0010\n","Epoch 40/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0020\n","Epoch 41/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0013\n","Epoch 42/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0010\n","Epoch 43/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","Epoch 44/50\n","39/39 [==============================] - 4s 100ms/step - loss: 8.2569e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","Epoch 46/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.1725e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.9492e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 94ms/step - loss: 9.8608e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","Epoch 50/50\n","39/39 [==============================] - 4s 95ms/step - loss: 6.9024e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb045b8edd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 103ms/step - loss: 0.1839\n","Epoch 2/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0052\n","Epoch 3/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0025\n","Epoch 4/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0024\n","Epoch 5/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0025\n","Epoch 6/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0016\n","Epoch 7/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0023\n","Epoch 8/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0019\n","Epoch 9/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0020\n","Epoch 10/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0019\n","Epoch 11/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 12/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 13/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 14/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0022\n","Epoch 15/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0022\n","Epoch 16/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0013\n","Epoch 17/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0016\n","Epoch 18/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0014\n","Epoch 19/50\n","39/39 [==============================] - 4s 102ms/step - loss: 0.0014\n","Epoch 20/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0013\n","Epoch 21/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0015\n","Epoch 22/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 23/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0012\n","Epoch 24/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0016\n","Epoch 25/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0017\n","Epoch 26/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0013\n","Epoch 27/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0018\n","Epoch 28/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0029\n","Epoch 29/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 30/50\n","39/39 [==============================] - 4s 96ms/step - loss: 9.0237e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0047\n","Epoch 32/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0022\n","Epoch 33/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0019\n","Epoch 34/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0013\n","Epoch 35/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0014\n","Epoch 36/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 37/50\n","39/39 [==============================] - 4s 102ms/step - loss: 0.0015\n","Epoch 38/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0013\n","Epoch 39/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0014\n","Epoch 40/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0022\n","Epoch 41/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","Epoch 42/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.2144e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0015\n","Epoch 44/50\n","39/39 [==============================] - 4s 96ms/step - loss: 9.2423e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0013\n","Epoch 46/50\n","39/39 [==============================] - 4s 96ms/step - loss: 9.4200e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.8455e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 96ms/step - loss: 9.7827e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 100ms/step - loss: 9.0262e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.9316e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb048cf95f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 96ms/step - loss: 0.1027\n","Epoch 2/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0046\n","Epoch 3/50\n","39/39 [==============================] - 4s 101ms/step - loss: 0.0040\n","Epoch 4/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0023\n","Epoch 5/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0023\n","Epoch 6/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0025\n","Epoch 7/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0019\n","Epoch 8/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0018\n","Epoch 9/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 10/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 11/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0015\n","Epoch 12/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0012\n","Epoch 13/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0017\n","Epoch 14/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0014\n","Epoch 15/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 16/50\n","39/39 [==============================] - 4s 95ms/step - loss: 9.9025e-04\n","Epoch 17/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0011\n","Epoch 18/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0015\n","Epoch 19/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0011\n","Epoch 20/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 21/50\n","39/39 [==============================] - 4s 104ms/step - loss: 0.0010\n","Epoch 22/50\n","39/39 [==============================] - 4s 97ms/step - loss: 8.8935e-04\n","Epoch 23/50\n","39/39 [==============================] - 4s 97ms/step - loss: 9.6288e-04\n","Epoch 24/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.0077e-04\n","Epoch 25/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0010\n","Epoch 26/50\n","39/39 [==============================] - 4s 97ms/step - loss: 7.2233e-04\n","Epoch 27/50\n","39/39 [==============================] - 4s 96ms/step - loss: 7.3838e-04\n","Epoch 28/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0011\n","Epoch 29/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0012\n","Epoch 30/50\n","39/39 [==============================] - 4s 101ms/step - loss: 8.3996e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 96ms/step - loss: 5.6540e-04\n","Epoch 32/50\n","39/39 [==============================] - 4s 96ms/step - loss: 7.4959e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 95ms/step - loss: 6.5702e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.6279e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 97ms/step - loss: 6.2629e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.7073e-04\n","Epoch 37/50\n","39/39 [==============================] - 4s 100ms/step - loss: 7.4054e-04\n","Epoch 38/50\n","39/39 [==============================] - 4s 101ms/step - loss: 5.9419e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 97ms/step - loss: 8.8167e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 97ms/step - loss: 5.5386e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 96ms/step - loss: 5.9201e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 95ms/step - loss: 5.9233e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 97ms/step - loss: 6.9377e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.8093e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 97ms/step - loss: 6.9909e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 99ms/step - loss: 4.9091e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 98ms/step - loss: 4.6954e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 95ms/step - loss: 5.0345e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 95ms/step - loss: 4.5935e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 95ms/step - loss: 7.1471e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb044360680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 7s 95ms/step - loss: 0.1446\n","Epoch 2/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0078\n","Epoch 3/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0079\n","Epoch 4/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0062\n","Epoch 5/50\n","39/39 [==============================] - 4s 102ms/step - loss: 0.0067\n","Epoch 6/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0057\n","Epoch 7/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0044\n","Epoch 8/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0087\n","Epoch 9/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0044\n","Epoch 10/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0038\n","Epoch 11/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0049\n","Epoch 12/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0036\n","Epoch 13/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0033\n","Epoch 14/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0041\n","Epoch 15/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0052\n","Epoch 16/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0035\n","Epoch 17/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0031\n","Epoch 18/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0033\n","Epoch 19/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0025\n","Epoch 20/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0032\n","Epoch 21/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0022\n","Epoch 22/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0026\n","Epoch 23/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 24/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0018\n","Epoch 25/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 26/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0017\n","Epoch 27/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0018\n","Epoch 28/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 29/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0013\n","Epoch 30/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0018\n","Epoch 31/50\n","39/39 [==============================] - 4s 100ms/step - loss: 0.0014\n","Epoch 32/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0040\n","Epoch 33/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0012\n","Epoch 34/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0012\n","Epoch 35/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0021\n","Epoch 36/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0012\n","Epoch 37/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0011\n","Epoch 38/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0013\n","Epoch 39/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0016\n","Epoch 40/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0011\n","Epoch 41/50\n","39/39 [==============================] - 4s 95ms/step - loss: 0.0010\n","Epoch 42/50\n","39/39 [==============================] - 4s 94ms/step - loss: 0.0012\n","Epoch 43/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0014\n","Epoch 44/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0014\n","Epoch 45/50\n","39/39 [==============================] - 4s 99ms/step - loss: 9.1089e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.7128e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 95ms/step - loss: 8.3392e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 96ms/step - loss: 9.3756e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 104ms/step - loss: 9.0830e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.7321e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb0474803b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/50\n","39/39 [==============================] - 8s 96ms/step - loss: 0.0981\n","Epoch 2/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0052\n","Epoch 3/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0016\n","Epoch 4/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0015\n","Epoch 5/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0014\n","Epoch 6/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0014\n","Epoch 7/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0013\n","Epoch 8/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0014\n","Epoch 9/50\n","39/39 [==============================] - 4s 99ms/step - loss: 0.0012\n","Epoch 10/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0013\n","Epoch 11/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0011\n","Epoch 12/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0026\n","Epoch 13/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0012\n","Epoch 14/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0013\n","Epoch 15/50\n","39/39 [==============================] - 4s 103ms/step - loss: 0.0011\n","Epoch 16/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0013\n","Epoch 17/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0014\n","Epoch 18/50\n","39/39 [==============================] - 4s 97ms/step - loss: 0.0022\n","Epoch 19/50\n","39/39 [==============================] - 4s 98ms/step - loss: 0.0012\n","Epoch 20/50\n","39/39 [==============================] - 4s 97ms/step - loss: 7.1915e-04\n","Epoch 21/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.3328e-04\n","Epoch 22/50\n","39/39 [==============================] - 4s 96ms/step - loss: 8.1230e-04\n","Epoch 23/50\n","39/39 [==============================] - 4s 100ms/step - loss: 9.6498e-04\n","Epoch 24/50\n","39/39 [==============================] - 4s 97ms/step - loss: 9.0007e-04\n","Epoch 25/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.9085e-04\n","Epoch 26/50\n","39/39 [==============================] - 4s 96ms/step - loss: 7.3869e-04\n","Epoch 27/50\n","39/39 [==============================] - 4s 97ms/step - loss: 6.6944e-04\n","Epoch 28/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.1729e-04\n","Epoch 29/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.4123e-04\n","Epoch 30/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.2261e-04\n","Epoch 31/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0026\n","Epoch 32/50\n","39/39 [==============================] - 4s 98ms/step - loss: 9.6231e-04\n","Epoch 33/50\n","39/39 [==============================] - 4s 97ms/step - loss: 6.2158e-04\n","Epoch 34/50\n","39/39 [==============================] - 4s 96ms/step - loss: 5.5414e-04\n","Epoch 35/50\n","39/39 [==============================] - 4s 95ms/step - loss: 5.0855e-04\n","Epoch 36/50\n","39/39 [==============================] - 4s 96ms/step - loss: 0.0032\n","Epoch 37/50\n","39/39 [==============================] - 4s 96ms/step - loss: 6.4332e-04\n","Epoch 38/50\n","39/39 [==============================] - 4s 95ms/step - loss: 5.0894e-04\n","Epoch 39/50\n","39/39 [==============================] - 4s 100ms/step - loss: 4.4446e-04\n","Epoch 40/50\n","39/39 [==============================] - 4s 96ms/step - loss: 4.0892e-04\n","Epoch 41/50\n","39/39 [==============================] - 4s 103ms/step - loss: 3.8854e-04\n","Epoch 42/50\n","39/39 [==============================] - 4s 96ms/step - loss: 4.2051e-04\n","Epoch 43/50\n","39/39 [==============================] - 4s 96ms/step - loss: 3.2577e-04\n","Epoch 44/50\n","39/39 [==============================] - 4s 95ms/step - loss: 4.0180e-04\n","Epoch 45/50\n","39/39 [==============================] - 4s 97ms/step - loss: 5.1014e-04\n","Epoch 46/50\n","39/39 [==============================] - 4s 95ms/step - loss: 4.5450e-04\n","Epoch 47/50\n","39/39 [==============================] - 4s 95ms/step - loss: 4.2020e-04\n","Epoch 48/50\n","39/39 [==============================] - 4s 96ms/step - loss: 3.8386e-04\n","Epoch 49/50\n","39/39 [==============================] - 4s 96ms/step - loss: 4.0699e-04\n","Epoch 50/50\n","39/39 [==============================] - 4s 96ms/step - loss: 3.9970e-04\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb043aee440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MbHBh4t_POth","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583809296,"user_tz":240,"elapsed":428,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"2bf66f36-6a33-432a-82b8-89d7ee412f97"},"source":["preds_list = [preds[i][0] for i in range(len(preds))]\n","start_price = [start_price[i][0] for i in range(len(start_price))]\n","\n","preds_list, start_price"],"execution_count":259,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([40.140266,\n","  105.65548,\n","  37.66195,\n","  75.13035,\n","  43.238846,\n","  25.50768,\n","  86.277885,\n","  164.23953,\n","  41.652267,\n","  10.059665,\n","  56.442726,\n","  78.65607,\n","  89.1984,\n","  22.064735,\n","  24.235039,\n","  2.1525023,\n","  139.0408,\n","  41.749596,\n","  104.97053,\n","  22.290682,\n","  13.360229,\n","  57.247185,\n","  30.510984,\n","  31.867573,\n","  66.10388],\n"," [41.839825,\n","  116.15669,\n","  33.90952,\n","  67.57211,\n","  47.939217,\n","  24.38828,\n","  87.626144,\n","  148.04132,\n","  45.994392,\n","  9.296078,\n","  61.586536,\n","  78.1213,\n","  112.973274,\n","  25.247786,\n","  29.466475,\n","  2.4226916,\n","  132.3915,\n","  40.43494,\n","  89.5247,\n","  22.866928,\n","  16.587347,\n","  66.09623,\n","  27.985971,\n","  34.308575,\n","  92.26885])"]},"metadata":{"tags":[]},"execution_count":259}]},{"cell_type":"code","metadata":{"id":"xWPqZLL108Za","executionInfo":{"status":"ok","timestamp":1619583834657,"user_tz":240,"elapsed":468,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}}},"source":["all_stocks_names = all_stocks['Name'].unique()[:25].tolist()\n","\n","df = pd.DataFrame({'Last Price':start_price, 'Predicted Price': preds_list}, index=all_stocks_names)"],"execution_count":261,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":824},"id":"Vnq6d3xb9N8j","executionInfo":{"status":"ok","timestamp":1619586638230,"user_tz":240,"elapsed":919,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"a9f153a5-f5ec-40d6-b72d-ba7a6d6301fb"},"source":["df"],"execution_count":273,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Last Price</th>\n","      <th>Predicted Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>AAL</th>\n","      <td>41.839825</td>\n","      <td>40.140266</td>\n","    </tr>\n","    <tr>\n","      <th>AAPL</th>\n","      <td>116.156693</td>\n","      <td>105.655479</td>\n","    </tr>\n","    <tr>\n","      <th>AAP</th>\n","      <td>33.909519</td>\n","      <td>37.661949</td>\n","    </tr>\n","    <tr>\n","      <th>ABBV</th>\n","      <td>67.572113</td>\n","      <td>75.130348</td>\n","    </tr>\n","    <tr>\n","      <th>ABC</th>\n","      <td>47.939217</td>\n","      <td>43.238846</td>\n","    </tr>\n","    <tr>\n","      <th>ABT</th>\n","      <td>24.388281</td>\n","      <td>25.507681</td>\n","    </tr>\n","    <tr>\n","      <th>ACN</th>\n","      <td>87.626144</td>\n","      <td>86.277885</td>\n","    </tr>\n","    <tr>\n","      <th>ADBE</th>\n","      <td>148.041321</td>\n","      <td>164.239532</td>\n","    </tr>\n","    <tr>\n","      <th>ADI</th>\n","      <td>45.994392</td>\n","      <td>41.652267</td>\n","    </tr>\n","    <tr>\n","      <th>ADM</th>\n","      <td>9.296078</td>\n","      <td>10.059665</td>\n","    </tr>\n","    <tr>\n","      <th>ADP</th>\n","      <td>61.586536</td>\n","      <td>56.442726</td>\n","    </tr>\n","    <tr>\n","      <th>ADSK</th>\n","      <td>78.121300</td>\n","      <td>78.656067</td>\n","    </tr>\n","    <tr>\n","      <th>ADS</th>\n","      <td>112.973274</td>\n","      <td>89.198402</td>\n","    </tr>\n","    <tr>\n","      <th>AEE</th>\n","      <td>25.247786</td>\n","      <td>22.064735</td>\n","    </tr>\n","    <tr>\n","      <th>AEP</th>\n","      <td>29.466475</td>\n","      <td>24.235039</td>\n","    </tr>\n","    <tr>\n","      <th>AES</th>\n","      <td>2.422692</td>\n","      <td>2.152502</td>\n","    </tr>\n","    <tr>\n","      <th>AET</th>\n","      <td>132.391495</td>\n","      <td>139.040802</td>\n","    </tr>\n","    <tr>\n","      <th>AFL</th>\n","      <td>40.434940</td>\n","      <td>41.749596</td>\n","    </tr>\n","    <tr>\n","      <th>AGN</th>\n","      <td>89.524696</td>\n","      <td>104.970528</td>\n","    </tr>\n","    <tr>\n","      <th>AIG</th>\n","      <td>22.866928</td>\n","      <td>22.290682</td>\n","    </tr>\n","    <tr>\n","      <th>AIV</th>\n","      <td>16.587347</td>\n","      <td>13.360229</td>\n","    </tr>\n","    <tr>\n","      <th>AIZ</th>\n","      <td>66.096230</td>\n","      <td>57.247185</td>\n","    </tr>\n","    <tr>\n","      <th>AJG</th>\n","      <td>27.985971</td>\n","      <td>30.510984</td>\n","    </tr>\n","    <tr>\n","      <th>AKAM</th>\n","      <td>34.308575</td>\n","      <td>31.867573</td>\n","    </tr>\n","    <tr>\n","      <th>ALB</th>\n","      <td>92.268852</td>\n","      <td>66.103882</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Last Price  Predicted Price\n","AAL    41.839825        40.140266\n","AAPL  116.156693       105.655479\n","AAP    33.909519        37.661949\n","ABBV   67.572113        75.130348\n","ABC    47.939217        43.238846\n","ABT    24.388281        25.507681\n","ACN    87.626144        86.277885\n","ADBE  148.041321       164.239532\n","ADI    45.994392        41.652267\n","ADM     9.296078        10.059665\n","ADP    61.586536        56.442726\n","ADSK   78.121300        78.656067\n","ADS   112.973274        89.198402\n","AEE    25.247786        22.064735\n","AEP    29.466475        24.235039\n","AES     2.422692         2.152502\n","AET   132.391495       139.040802\n","AFL    40.434940        41.749596\n","AGN    89.524696       104.970528\n","AIG    22.866928        22.290682\n","AIV    16.587347        13.360229\n","AIZ    66.096230        57.247185\n","AJG    27.985971        30.510984\n","AKAM   34.308575        31.867573\n","ALB    92.268852        66.103882"]},"metadata":{"tags":[]},"execution_count":273}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"Oa3ONu8S4NL_","executionInfo":{"status":"ok","timestamp":1619586645001,"user_tz":240,"elapsed":467,"user":{"displayName":"Parth Mishra","photoUrl":"","userId":"00791656219792042383"}},"outputId":"a2f7c9e6-333a-490e-de68-c67505f6fedc"},"source":["from google.colab import files\n","\n","df.to_csv('df.csv')\n","files.download('df.csv')"],"execution_count":274,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_097026a2-25d2-4cdc-b60f-032b90cb695a\", \"df.csv\", 1055)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Bd7ypBJm4vnr"},"source":[""],"execution_count":null,"outputs":[]}]}